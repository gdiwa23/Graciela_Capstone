{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87a679fa-6fb6-4c60-b963-dbf74a938df2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Logging in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fb3c81-38c6-48bc-b2cf-646fec43f8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set values\n",
    "PROJECT_ID=\"rm-imagen-vertex\" ## your proj name\n",
    "BILLING_ACCOUNT=\"ur billing account num\"   # find with: gcloud billing accounts list\n",
    "LOCATION=\"us-central1\" # set location, this is where imagen serves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1af7965-fa71-42cf-acb6-4b9cf022eaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# issues logging in check this\n",
    "\n",
    "#! gcloud billing accounts list\n",
    "#! gcloud auth login\n",
    "\n",
    "\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()   # pops a Google login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135dada2-ce03-476c-ac5f-d05ddcf09a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set active project\n",
    "!gcloud config set project \"$PROJECT_ID\"\n",
    "\n",
    "# Link billing\n",
    "!gcloud billing projects link \"$PROJECT_ID\" --billing-account=\"$BILLING_ACCOUNT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dc21c2-acf4-450c-a2a6-2ca16561dc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable Vertex AI API\n",
    "! gcloud services enable aiplatform.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641eeb8e-6d2f-4109-94ed-138796b48da7",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "* connect to gemini and Google cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c260c5-2b5b-4ffb-825c-050dc8e26698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U google-generativeai\n",
    "import google.generativeai as genai\n",
    "\n",
    "from vertexai import init\n",
    "from vertexai.generative_models import GenerativeModel ## for the prompts\n",
    "from vertexai.preview.vision_models import ImageGenerationModel ## prompts->imagen\n",
    "\n",
    "# \n",
    "import random\n",
    "import time\n",
    "import json\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "\n",
    "\n",
    "#initiate\n",
    "init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b6a229-75b9-4958-9a2d-4eb6cbba790b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# switching to google generativeai\n",
    "GEMINI_API_KEY=\"your API key\"\n",
    "\n",
    "#initiate\n",
    "init(project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "\n",
    "\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "model = genai.GenerativeModel(\"gemini-2.0-flash\")  # or \"gemini-2.0-pro\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53869078-0f79-4d98-95ce-079d9a359e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = model.generate_content(\"hello gemini ?\")\n",
    "print(resp.text) # check connection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7095cc4-5da5-416b-a538-80671b53c9d1",
   "metadata": {},
   "source": [
    "## Step 1: Gemini to sort descriptors -> JSON\n",
    "* using extracted_descriptors2\n",
    "* get gemini to sort the extracted dscriptors to the best matching category\n",
    "    *  eg 'sharp' to 'teeth'\n",
    "    *  resulting in JSONs\n",
    "* included very detailed instructions to gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d140f2d-8eed-4e57-8a73-65e90d9b91b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = pd.read_csv(\"extracted_descriptors2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18573fcc-5c48-41c6-9dd3-d58b88e45d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------1-------\n",
    "\n",
    "# setting out what needs to be matched\n",
    "# descriptive buckets\n",
    "BUCKETS = [\n",
    "    \"colour\",\n",
    "    \"patterns\",\n",
    "    \"shape\",\n",
    "    \"mouth_teeth\",\n",
    "    \"special_features\",\n",
    "    \"personality\",\n",
    "]\n",
    "\n",
    "#response outline\n",
    "RESPONSE_SCHEMA = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"colour\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
    "        \"patterns\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
    "        \"shape\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
    "        \"mouth_teeth\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
    "        \"special_features\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
    "        \"personality\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
    "        \"unused_terms\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}}\n",
    "    },\n",
    "    \"required\": BUCKETS\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "SYSTEM_RULES = \"\"\"Focus on matching the descriptors to the physical attributes.\n",
    "You are categorizing short fish descriptors into predefined visual/style buckets for image generation.\n",
    "Work only with the exact descriptors provided — do not invent new descriptors or add concepts.\n",
    "\n",
    "RULES:\n",
    "- Each descriptor must go into exactly one bucket, or \"uncategorized\" if it does not fit.\n",
    "- If a descriptor matches multiple buckets, assign it to the single most specific and relevant one.\n",
    "- Prioritize matches in this order if ambiguous: colour > patterns > shape > mouth_teeth > special_features > personality.\n",
    "\n",
    "BUCKETS:\n",
    "- **colour**: words about hue/shade/tint, e.g. grey, silver, olive, golden, blue, dark, pale, black, white, red, brown, yellow, green.\n",
    "- **patterns**: surface markings, e.g. striped, spotted, mottled, banded, blotched, patterned.\n",
    "- **shape**: global body form/outline, e.g. elongated, flat, torpedo, round, slender, bulky, compressed, streamlined.\n",
    "- **mouth_teeth**: anything about teeth, jaws, sharpness, or biting structures, e.g. teeth, fangs, jaws, jaw, sharp, barbed, toothed, mouth.\n",
    "- **special_features**: anatomical structures or standout traits, e.g. spines, whiskers, barbels, fins, armour/armor, bioluminescent, tail, gills, scales, stinger, plates.\n",
    "- **personality**: behavior or perceived character, e.g. ferocious, timid, aggressive, curious, docile, fearsome, elusive, mysterious, bold, shy.\n",
    "- **uncategorized**: fallback bucket if no category is clearly appropriate.\n",
    "\n",
    "IMPORTANT:\n",
    "- Never generate or invent descriptors beyond those provided.\n",
    "- Always return descriptors grouped under their bucket labels.\n",
    "- Keep descriptors exactly as given (no rewriting).\n",
    "- Ensure that descriptors in the same bucket do not share similar words.\n",
    "\n",
    "Return only JSON following the provided schema. Use lower-case single words or short phrases; no punctuation .\n",
    "If a bucket has nothing, return an empty array for that bucket .\n",
    "Also return 'unused_terms' with any descriptors you did not use.\n",
    "\n",
    "Use exactly these keys: colour, patterns, shape, mouth_teeth, special_features, personality, unused_terms.\n",
    "Map terms to buckets in JSON format strictly.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "#- Only use words that appear in the provided descriptors (and optional wiki terms); DO NOT invent new concepts. (og)\n",
    "\n",
    "## function for doing alladat\n",
    "\n",
    "\n",
    "\n",
    "def classify_descriptors_with_gemini(transcript_top, wiki_top, max_items_per_bucket=2):\n",
    "    input_desc = {\n",
    "        \"transcript_top\": transcript_top or [],\n",
    "        \"wiki_top\": wiki_top or [],\n",
    "    }\n",
    "\n",
    "    #model = genai.GenerativeModel(\"gemini-2.0-flash\")  # or \"gemini-2.0-pro\"\n",
    "\n",
    "    resp = model.generate_content(\n",
    "        [\n",
    "            SYSTEM_RULES,\n",
    "            f\"Max {max_items_per_bucket} items per bucket. Map these terms:\\n{input_desc}\"\n",
    "        ],\n",
    "        generation_config={\n",
    "            \"temperature\": 0.2,\n",
    "            \"top_p\": 0.95,\n",
    "            \"max_output_tokens\": 1024,\n",
    "            \"response_mime_type\": \"application/json\",\n",
    "            \"response_schema\": RESPONSE_SCHEMA,  # ✅ dict works here\n",
    "        },\n",
    "    )\n",
    "\n",
    "\n",
    "    # Parse JSON\n",
    "    data = json.loads(resp.text)\n",
    "\n",
    "    # Normalize + cap\n",
    "    for k in BUCKETS:\n",
    "        data[k] = [t.strip().lower() for t in data.get(k, [])][:max_items_per_bucket]\n",
    "    data[\"unused_terms\"] = [t.strip().lower() for t in data.get(\"unused_terms\", [])]\n",
    "\n",
    "    # pause to avoid quota errors\n",
    "    delay = random.uniform(2, 4)\n",
    "    print(f\"Sleeping for {delay:.1f} seconds (rate limiting)...\")\n",
    "    time.sleep(delay)\n",
    "\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa5bc96-3f2a-4081-94c7-fa44ee4e7073",
   "metadata": {},
   "source": [
    "## Step 2: From the JSONs, build standard prompts\n",
    "* included a variety of phrasings, core instructions and styles to add some variations\n",
    "  * found very useful to stop generic and same looking fish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59b1c58-c987-4978-a7b6-e27de69b7626",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phrase_bucket(name, items):\n",
    "    phrasing = {\n",
    "        \"colour\": [\"with scales in shades of {}\", \"coloured {}\", \"a body of {} hues\"],\n",
    "        \"patterns\": [\"showing {} markings\", \"{} body pattern\", \"distinctly {}\"],\n",
    "        \"shape\": [\"with a {} form\", \"shaped {}\", \"{} body\"],\n",
    "        \"mouth_teeth\": [\"{}\", \"with {}\"],\n",
    "        \"special_features\": [\"notable for {}\", \"showing {}\", \"characterised by {}\"],\n",
    "        \"personality\": [\"giving off a {} vibe\", \"appearing {}\", \"a {} presence\"],\n",
    "    }\n",
    "    if name not in phrasing:\n",
    "        return f\"{name}: {', '.join(items)}\"\n",
    "    template = random.choice(phrasing[name])\n",
    "    return template.format(\", \".join(items))\n",
    "\n",
    "core = [\n",
    "    \"illustration of a giant freshwater fish\",\n",
    "    \"cinematic portrait of a mysterious river fish\",\n",
    "    \"detailed biological illustration of a freshwater predator\",\n",
    "    \"dynamic scene of a strange predatory fish lurking underwater\",\n",
    "    'image of a giant freshwater predator fish '\n",
    "]\n",
    "\n",
    "\n",
    "style = [\n",
    "    \"hyper-realistic, cinematic, dramatic lighting, murky river background\",\n",
    "    \"true to like, anatomical accuracy, dark waters background\",\n",
    "    \"artistic rendering, surreal, moody atmosphere, deep shadows\",\n",
    "    \"photorealistic, high detail on textures and skin, full body\",\n",
    "]\n",
    "\n",
    "def buckets_to_prompt(buckets: dict) -> str:\n",
    "    \"\"\"Craft a more varied, image-ready prompt from buckets.\"\"\"\n",
    "    lines = []\n",
    "\n",
    "    for key in [\"colour\", \"patterns\", \"shape\", \"mouth_teeth\", \"special_features\", \"personality\"]:\n",
    "        if buckets.get(key):\n",
    "            lines.append(phrase_bucket(key, buckets[key]))\n",
    "\n",
    "    core_choice = random.choice(core)\n",
    "    style_choice = random.choice(style)\n",
    "    detail_choice = \"; \".join(lines) if lines else \"neutral appearance\"\n",
    "\n",
    "    return f\"{core_choice}, {detail_choice}. Style: {style_choice}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbf9575-fe38-41a4-a0a5-4579da6c1bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the prompts -- wrapper\n",
    "\n",
    "def generate_from_desc1(df: pd.DataFrame, max_items_per_bucket=2) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each row in df, classify transcript_top/wiki_top descriptors and\n",
    "    build prompts. Adds four new columns:\n",
    "    transcript_bucket, wiki_bucket, transcript_prompt, wiki_prompt\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    transcript_buckets = []\n",
    "    wiki_buckets = []\n",
    "    transcript_prompts = []\n",
    "    wiki_prompts = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        tb = classify_descriptors_with_gemini(row[\"transcript_top\"], max_items_per_bucket)\n",
    "        wb = classify_descriptors_with_gemini(row[\"wiki_top\"], max_items_per_bucket)\n",
    "\n",
    "        transcript_buckets.append(tb)\n",
    "        wiki_buckets.append(wb)\n",
    "        transcript_prompts.append(buckets_to_prompt(tb))\n",
    "        wiki_prompts.append(buckets_to_prompt(wb))\n",
    "\n",
    "        #timesleep, embedded in func\n",
    "\n",
    "    df[\"transcript_bucket\"] = transcript_buckets\n",
    "    df[\"wiki_bucket\"] = wiki_buckets\n",
    "    df[\"transcript_prompt\"] = transcript_prompts\n",
    "    df[\"wiki_prompt\"] = wiki_prompts\n",
    "\n",
    "    print('Complete!')\n",
    "\n",
    "    return df\n",
    "\n",
    "# in use\n",
    "#prompts_df2 = generate_from_desc1(df_2, max_items_per_bucket=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6a990e-1e7a-4b4c-8a87-85e95b873af6",
   "metadata": {},
   "source": [
    "## Step 3: generate the images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80913282-a81a-4c3c-b9af-f4a303c4ad6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generates and saves the images\n",
    "\n",
    "def one_image_with_imagen(prompt, prefix, model_name=\"imagen-3.0-generate-001\"):\n",
    "    \"\"\"\n",
    "    Generate one image with Imagen (v3 if available, fallback to Imagen 2) and save it.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Try Imagen v3\n",
    "        imagen = ImageGenerationModel.from_pretrained(model_name)\n",
    "        resp = imagen.generate_images(prompt=prompt, number_of_images=1)\n",
    "    except Exception as e:\n",
    "        print(f\"[warn] {model_name} failed ({e}). Trying Imagen 2...\")\n",
    "        imagen = ImageGenerationModel(\"imagegeneration@002\")\n",
    "        resp = imagen.generate_images(prompt=prompt)\n",
    "\n",
    "    # --- Handle Imagen response ---\n",
    "    if hasattr(resp, \"images\") and resp.images:  # Imagen v3 style\n",
    "        img = resp.images[0]\n",
    "        out = f\"{prefix}.png\"\n",
    "        with open(out, \"wb\") as f:\n",
    "            f.write(img._image_bytes)\n",
    "        print(f\"✅ Saved image as: {out}\")\n",
    "        return out\n",
    "\n",
    "    # --- Handle legacy/fallback response ---\n",
    "    if hasattr(resp, \"candidates\"):  # Imagen 2 style\n",
    "        for part in resp.candidates[0].content.parts:\n",
    "            if hasattr(part, \"inline_data\") and getattr(part.inline_data, \"mime_type\", \"\").startswith(\"image/\"):\n",
    "                data = part.inline_data.data\n",
    "                out = f\"{prefix}.png\"\n",
    "                with open(out, \"wb\") as f:\n",
    "                    f.write(data)\n",
    "                print(f\"✅ Saved image as: {out}\")\n",
    "                return out\n",
    "\n",
    "    print(\"⚠️ No image returned.\")\n",
    "    return None\n",
    "\n",
    "\n",
    "# uses promptsdf\n",
    "\n",
    "def df_prompt_imagen(df):\n",
    "  '''\n",
    "  Ensure that the df has the columns:\n",
    "  transcript_prompt, wiki_prompt\n",
    "  '''\n",
    "\n",
    "  df = df.copy()\n",
    "\n",
    "  transcript_images = []\n",
    "  wiki_images = []\n",
    "\n",
    "  for _, row in df.iterrows():\n",
    "\n",
    "    english_name = str(row[\"english_name\"]).replace(\" \", \"_\").lower()\n",
    "    latin_name = str(row[\"latin_name\"]).replace(\" \", \"_\").lower()\n",
    "\n",
    "    # generate images\n",
    "    ti = one_image_with_imagen(row[\"transcript_prompt\"], prefix=f\"{english_name}_transcript\")\n",
    "    transcript_images.append(ti)\n",
    "    print(f\"{english_name} image generated!\")\n",
    "\n",
    "    # sleep to avoid spikes\n",
    "    delay = random.uniform(10,20)\n",
    "    time.sleep(delay)\n",
    "    print(f\"Sleeping for {delay:.1f} seconds...\")\n",
    "\n",
    "    wi = one_image_with_imagen(row[\"wiki_prompt\"], prefix=f\"{latin_name}_wiki\")\n",
    "    wiki_images.append(wi)\n",
    "    print(f\"{latin_name} image generated!\")\n",
    "\n",
    "        # sleep to avoid spikes\n",
    "    delay = random.uniform(10,20)\n",
    "    time.sleep(delay)\n",
    "    print(f\"Sleeping for {delay:.1f} seconds...\")\n",
    "\n",
    "\n",
    "  df[\"transcript_image\"] = transcript_images\n",
    "  df[\"wiki_image\"] = wiki_images\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b435630-78c0-42ee-8061-0a677ae27aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompts_df = prompts_df2.copy()\n",
    "#prompts_df = df_prompt_imagen(prompts_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
